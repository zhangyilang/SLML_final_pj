\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Related Work}{}% 2
\BOOKMARK [1][-]{section.3}{Discussion of Proposed Models}{}% 3
\BOOKMARK [2][-]{subsection.3.1}{Analysis and Inspiration}{section.3}% 4
\BOOKMARK [2][-]{subsection.3.2}{Proposed Structures and Experiments}{section.3}% 5
\BOOKMARK [3][-]{subsubsection.3.2.1}{Multi-head attention}{subsection.3.2}% 6
\BOOKMARK [3][-]{subsubsection.3.2.2}{Layer Normalization}{subsection.3.2}% 7
\BOOKMARK [3][-]{subsubsection.3.2.3}{Bi-directional LSTM}{subsection.3.2}% 8
\BOOKMARK [3][-]{subsubsection.3.2.4}{Multi-scale Convolution in Features}{subsection.3.2}% 9
\BOOKMARK [2][-]{subsection.3.3}{Our Final Model: Self Attentive Multi-scale LSTM \(SM-LSTM\)}{section.3}% 10
\BOOKMARK [1][-]{section.4}{Experiments of SM-LSTM}{}% 11
\BOOKMARK [2][-]{subsection.4.1}{Loss function}{section.4}% 12
\BOOKMARK [2][-]{subsection.4.2}{Preprocessing}{section.4}% 13
\BOOKMARK [2][-]{subsection.4.3}{Capped Gradient}{section.4}% 14
\BOOKMARK [2][-]{subsection.4.4}{Parameters}{section.4}% 15
\BOOKMARK [1][-]{section.5}{Results and Analysis}{}% 16
\BOOKMARK [1][-]{section.6}{Further Improvements}{}% 17
